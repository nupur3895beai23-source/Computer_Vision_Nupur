{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üåø Lab 2.2: Transfer Learning with ResNet50\n",
    "**Module 3: Computer Vision and Image Processing**\n",
    "B-Tech AI Specialization | Chitkara University | February 2026\n",
    "\n",
    "---\n",
    "\n",
    "## üåæ Industry Scenario\n",
    "> You have **500 images** of 5 types of plant diseases. A farmer app needs a classifier to identify diseases from phone photos. Training from scratch would take days and thousands of images. **Transfer learning** lets you adapt a model that already understands images to your specific task ‚Äî quickly.\n",
    "\n",
    "## üéØ Objective\n",
    "Fine-tune a pre-trained ResNet50 on a small plant disease dataset. Compare against training from scratch. Target: **‚â•80% validation accuracy in 10 epochs**.\n",
    "\n",
    "**Time:** 120 minutes | **Mode:** Individual\n",
    "\n",
    "---\n",
    "### üìã Lab Flow\n",
    "| Stage | What happens |\n",
    "|---|---|\n",
    "| ü§î Predict | Answer before coding ‚Äî commit to a guess |\n",
    "| üíª Code | Fill in the `TODO` sections |\n",
    "| üí° Reveal | Click to check hint or full solution |\n",
    "| üéöÔ∏è Explore | Interactive plots ‚Äî dig into your results |\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Setup ‚Äî Run First"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import output\n",
    "output.enable_custom_widget_manager()\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import History\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML, Code\n",
    "import os, time, warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"TensorFlow : {tf.__version__}\")\n",
    "print(f\"GPU available: {len(tf.config.list_physical_devices('GPU')) > 0}\")\n",
    "print(\"‚úÖ Ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reveal_button(hint_text, solution_code):\n",
    "    import ipywidgets as widgets\n",
    "    from IPython.display import display, HTML, Code\n",
    "    out = widgets.Output()\n",
    "    hint_btn = widgets.Button(description='üí° Hint', button_style='info',\n",
    "        layout=widgets.Layout(width='120px', margin='4px'))\n",
    "    sol_btn  = widgets.Button(description='‚úÖ Solution', button_style='warning',\n",
    "        layout=widgets.Layout(width='140px', margin='4px'))\n",
    "    hide_btn = widgets.Button(description='üôà Hide', button_style='',\n",
    "        layout=widgets.Layout(width='100px', margin='4px'))\n",
    "    def on_hint(b):\n",
    "        with out:\n",
    "            out.clear_output(wait=True)\n",
    "            display(HTML(f'<div style=\"background:#e3f2fd;padding:12px;border-radius:6px;'\n",
    "                f'border-left:4px solid #1976D2;font-size:14px\"><b>üí° Hint:</b><br>{hint_text}</div>'))\n",
    "    def on_sol(b):\n",
    "        with out:\n",
    "            out.clear_output(wait=True)\n",
    "            display(HTML('<b>‚úÖ Solution:</b>'))\n",
    "            display(Code(solution_code, language='python'))\n",
    "    def on_hide(b):\n",
    "        with out: out.clear_output()\n",
    "    hint_btn.on_click(on_hint); sol_btn.on_click(on_sol); hide_btn.on_click(on_hide)\n",
    "    display(widgets.HBox([hint_btn, sol_btn, hide_btn]), out)\n",
    "\n",
    "print(\"reveal_button() ready ‚úÖ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 1: Prepare the Dataset\n",
    "\n",
    "We'll use a small subset of the **PlantVillage** dataset ‚Äî 5 plant disease classes, 100 images each.\n",
    "\n",
    "### ü§î Predict First\n",
    "Before running any code, answer these:\n",
    "1. We have 500 images total. How many will be in train vs. validation (80/20 split)?\n",
    "2. Why do we need validation data at all ‚Äî why not just train on everything?\n",
    "3. What problems could arise with only 100 images per class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úèÔ∏è Your predictions (as comments):\n",
    "# 1. Train: ___   Validation: ___\n",
    "# 2. Validation is needed because...\n",
    "# 3. With only 100 images per class, the risk is..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üíª Download and Organise the Dataset\n",
    "We'll download a pre-prepared subset from a public source and set up directory structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dataset ‚Äî this creates a folder structure:\n",
    "# data/\n",
    "#   train/\n",
    "#     Tomato_Bacterial_spot/  (80 images)\n",
    "#     Tomato_Early_blight/    (80 images)\n",
    "#     ... (5 classes total)\n",
    "#   val/\n",
    "#     Tomato_Bacterial_spot/  (20 images)\n",
    "#     ...\n",
    "\n",
    "import urllib.request, zipfile\n",
    "\n",
    "DATA_URL  = \"https://github.com/btphan95/greenr-dataset/raw/master/data.zip\"\n",
    "DATA_DIR  = \"plant_disease_data\"\n",
    "\n",
    "# TODO: Download and extract the dataset\n",
    "# Uncomment and complete:\n",
    "# if not os.path.exists(DATA_DIR):\n",
    "#     print(\"Downloading dataset...\")\n",
    "#     urllib.request.urlretrieve(DATA_URL, \"data.zip\")\n",
    "#     with zipfile.ZipFile(\"data.zip\", 'r') as z:\n",
    "#         z.extractall(DATA_DIR)\n",
    "#     print(\"Extracted ‚úÖ\")\n",
    "\n",
    "# --- ALTERNATIVE: If the URL above doesn't work, use tf.keras.utils.get_file ---\n",
    "# dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
    "# data_dir = tf.keras.utils.get_file('flower_photos', origin=dataset_url, untar=True)\n",
    "\n",
    "# TODO: Set your train and validation directory paths\n",
    "TRAIN_DIR = None   # e.g. os.path.join(DATA_DIR, 'train')\n",
    "VAL_DIR   = None   # e.g. os.path.join(DATA_DIR, 'val')\n",
    "\n",
    "# Quick check ‚Äî print class names and image counts\n",
    "if TRAIN_DIR and os.path.exists(TRAIN_DIR):\n",
    "    classes = sorted(os.listdir(TRAIN_DIR))\n",
    "    print(f\"Classes found ({len(classes)}): {classes}\")\n",
    "    for cls in classes:\n",
    "        n = len(os.listdir(os.path.join(TRAIN_DIR, cls)))\n",
    "        print(f\"  {cls}: {n} training images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reveal_button(\n",
    "    hint_text=\"Use <code>urllib.request.urlretrieve(url, filename)</code> to download, \"\n",
    "              \"then <code>zipfile.ZipFile</code> to extract. Set TRAIN_DIR and VAL_DIR \"\n",
    "              \"to point at the <code>train/</code> and <code>val/</code> subdirectories.\",\n",
    "    solution_code=(\n",
    "        \"if not os.path.exists(DATA_DIR):\\n\"\n",
    "        \"    urllib.request.urlretrieve(DATA_URL, 'data.zip')\\n\"\n",
    "        \"    with zipfile.ZipFile('data.zip', 'r') as z:\\n\"\n",
    "        \"        z.extractall(DATA_DIR)\\n\\n\"\n",
    "        \"TRAIN_DIR = os.path.join(DATA_DIR, 'train')\\n\"\n",
    "        \"VAL_DIR   = os.path.join(DATA_DIR, 'val')\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 2: Data Augmentation\n",
    "\n",
    "With only ~80 training images per class, we need to artificially expand the dataset using **augmentation** ‚Äî creating modified versions of each image on the fly during training.\n",
    "\n",
    "### ü§î Predict First\n",
    "Look at the augmentation parameters below. For each one, predict:\n",
    "- What does it do visually to the image?\n",
    "- Does it make sense for plant disease photos? (Would a real phone photo look like this?)\n",
    "\n",
    "| Parameter | Your prediction | Makes sense? |\n",
    "|---|---|---|\n",
    "| `horizontal_flip=True` | ? | ? |\n",
    "| `rotation_range=20` | ? | ? |\n",
    "| `zoom_range=0.2` | ? | ? |\n",
    "| `width_shift_range=0.1` | ? | ? |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úèÔ∏è Fill in your predictions in the table above (edit the markdown cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üíª Build the Data Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE  = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# TODO: Create an ImageDataGenerator for TRAINING with augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    # horizontal_flip=...,\n",
    "    # rotation_range=...,\n",
    "    # zoom_range=...,\n",
    "    # width_shift_range=...,\n",
    "    # height_shift_range=...,\n",
    ")\n",
    "\n",
    "# TODO: Create a separate generator for VALIDATION ‚Äî no augmentation, just preprocessing\n",
    "val_datagen = ImageDataGenerator(\n",
    "    # preprocessing_function=...\n",
    ")\n",
    "\n",
    "# TODO: Create the flow_from_directory generators\n",
    "train_generator = None\n",
    "# train_generator = train_datagen.flow_from_directory(\n",
    "#     TRAIN_DIR,\n",
    "#     target_size=IMG_SIZE,\n",
    "#     batch_size=BATCH_SIZE,\n",
    "#     class_mode='categorical'\n",
    "# )\n",
    "\n",
    "val_generator = None\n",
    "# val_generator = val_datagen.flow_from_directory(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reveal_button(\n",
    "    hint_text=\"Validation generator should have <b>no augmentation</b> ‚Äî only <code>preprocessing_function</code>. \"\n",
    "              \"Augmenting validation data would give you unrealistic accuracy scores.\",\n",
    "    solution_code=(\n",
    "        \"train_datagen = ImageDataGenerator(\\n\"\n",
    "        \"    preprocessing_function=preprocess_input,\\n\"\n",
    "        \"    horizontal_flip=True,\\n\"\n",
    "        \"    rotation_range=20,\\n\"\n",
    "        \"    zoom_range=0.2,\\n\"\n",
    "        \"    width_shift_range=0.1,\\n\"\n",
    "        \"    height_shift_range=0.1\\n\"\n",
    "        \")\\n\\n\"\n",
    "        \"val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\\n\\n\"\n",
    "        \"train_generator = train_datagen.flow_from_directory(\\n\"\n",
    "        \"    TRAIN_DIR, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode='categorical'\\n\"\n",
    "        \")\\n\"\n",
    "        \"val_generator = val_datagen.flow_from_directory(\\n\"\n",
    "        \"    VAL_DIR, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode='categorical'\\n\"\n",
    "        \")\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéöÔ∏è Explore: What Does Augmentation Actually Do?\n",
    "Run the cell below to visualise 8 augmented versions of the same image side-by-side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise augmentation ‚Äî see what the model actually trains on\n",
    "sample_batch, _ = next(train_generator)\n",
    "sample_img_raw  = sample_batch[0]\n",
    "\n",
    "# Un-preprocess for display (ResNet50 uses mean subtraction, not [0,1] scaling)\n",
    "def unpreprocess(img):\n",
    "    img = img.copy()\n",
    "    img[..., 0] += 103.939\n",
    "    img[..., 1] += 116.779\n",
    "    img[..., 2] += 123.68\n",
    "    return np.clip(img[..., ::-1] / 255.0, 0, 1)  # BGR ‚Üí RGB\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "fig.suptitle(\"8 Augmented Versions of the Same Image\\n\"\n",
    "             \"(What the model sees during training)\", fontsize=13, fontweight='bold')\n",
    "\n",
    "aug_gen = train_datagen.flow(\n",
    "    np.expand_dims(sample_batch[0], 0), batch_size=1\n",
    ")\n",
    "for ax in axes.flat:\n",
    "    aug_img = next(aug_gen)[0]\n",
    "    ax.imshow(unpreprocess(aug_img))\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(\"‚úèÔ∏è Observation: How different do these look from each other?\")\n",
    "print(\"   Would you expect a plant photo from a phone to look like these?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 3: Build the Transfer Learning Model (Feature Extraction Phase)\n",
    "\n",
    "Transfer learning has two phases:\n",
    "\n",
    "```\n",
    "Phase 1 ‚Äî Feature Extraction:\n",
    "  ResNet50 (frozen, pretrained) ‚Üí GlobalAveragePooling ‚Üí Dense ‚Üí Softmax\n",
    "  ‚Üë weights locked, won't change              ‚Üë only these train\n",
    "\n",
    "Phase 2 ‚Äî Fine-tuning:\n",
    "  ResNet50 (last 20 layers UNfrozen) ‚Üí GlobalAveragePooling ‚Üí Dense ‚Üí Softmax\n",
    "  ‚Üë these now also update, but slowly\n",
    "```\n",
    "\n",
    "### ü§î Predict First\n",
    "1. Why do we **freeze** ResNet50's layers in Phase 1?\n",
    "2. Why do we need `include_top=False`?\n",
    "3. What does `GlobalAveragePooling2D` do differently from `Flatten`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úèÔ∏è Your predictions:\n",
    "# 1. We freeze because...\n",
    "# 2. include_top=False means...\n",
    "# 3. GlobalAveragePooling vs Flatten:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üíª Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 5   # adjust if your dataset has a different number\n",
    "\n",
    "# TODO: Load ResNet50 base ‚Äî no top, pretrained on ImageNet\n",
    "base_model = ResNet50(\n",
    "    # weights=...,\n",
    "    # include_top=...,\n",
    "    # input_shape=...\n",
    ")\n",
    "\n",
    "# TODO: Freeze all base model layers so they don't update during Phase 1\n",
    "# base_model.trainable = ...\n",
    "\n",
    "# TODO: Build the full model by adding a classification head\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    # layers.GlobalAveragePooling2D(),\n",
    "    # layers.Dense(256, activation='relu'),\n",
    "    # layers.Dropout(0.5),\n",
    "    # layers.Dense(NUM_CLASSES, activation='softmax'),\n",
    "])\n",
    "\n",
    "# TODO: Compile with adam and categorical_crossentropy\n",
    "# model.compile(...)\n",
    "\n",
    "# Check: how many layers are trainable?\n",
    "trainable   = sum(1 for l in model.layers[0].layers if l.trainable)\n",
    "untrainable = sum(1 for l in model.layers[0].layers if not l.trainable)\n",
    "print(f\"ResNet50 layers ‚Äî Trainable: {trainable} | Frozen: {untrainable}\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reveal_button(\n",
    "    hint_text=\"Set <code>base_model.trainable = False</code> after loading. \"\n",
    "              \"Then stack: <code>GlobalAveragePooling2D ‚Üí Dense(256, relu) ‚Üí Dropout(0.5) ‚Üí Dense(NUM_CLASSES, softmax)</code>.\",\n",
    "    solution_code=(\n",
    "        \"base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\\n\"\n",
    "        \"base_model.trainable = False\\n\\n\"\n",
    "        \"model = models.Sequential([\\n\"\n",
    "        \"    base_model,\\n\"\n",
    "        \"    layers.GlobalAveragePooling2D(),\\n\"\n",
    "        \"    layers.Dense(256, activation='relu'),\\n\"\n",
    "        \"    layers.Dropout(0.5),\\n\"\n",
    "        \"    layers.Dense(NUM_CLASSES, activation='softmax'),\\n\"\n",
    "        \"])\\n\\n\"\n",
    "        \"model.compile(\\n\"\n",
    "        \"    optimizer=optimizers.Adam(learning_rate=1e-3),\\n\"\n",
    "        \"    loss='categorical_crossentropy',\\n\"\n",
    "        \"    metrics=['accuracy']\\n\"\n",
    "        \")\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 4: Phase 1 ‚Äî Train the Classification Head (10 epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Train the model for 10 epochs\n",
    "# history_phase1 = model.fit(\n",
    "#     train_generator,\n",
    "#     epochs=10,\n",
    "#     validation_data=val_generator\n",
    "# )\n",
    "\n",
    "history_phase1 = None  # replace with model.fit(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reveal_button(\n",
    "    hint_text=\"Call <code>model.fit(train_generator, epochs=10, validation_data=val_generator)</code>. \"\n",
    "              \"Store the result in <code>history_phase1</code>.\",\n",
    "    solution_code=(\n",
    "        \"history_phase1 = model.fit(\\n\"\n",
    "        \"    train_generator,\\n\"\n",
    "        \"    epochs=10,\\n\"\n",
    "        \"    validation_data=val_generator\\n\"\n",
    "        \")\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Task 5: Phase 2 ‚Äî Fine-Tuning (Unfreeze Last 20 Layers)\n",
    "\n",
    "Now we'll carefully unfreeze the **last 20 layers** of ResNet50 and train them at a very low learning rate. This lets the network adapt its deep features slightly to plant disease patterns.\n",
    "\n",
    "### ü§î Predict First\n",
    "1. Why must the learning rate be **much lower** in fine-tuning (1e-5 vs 1e-3)?\n",
    "2. Why do we unfreeze only the **last** layers, not the first?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úèÔ∏è Your predictions:\n",
    "# 1. Lower LR because...\n",
    "# 2. Last layers because..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Unfreeze the last 20 layers of the base model\n",
    "base_model = model.layers[0]  # get the ResNet50 sub-model\n",
    "\n",
    "# Step 1: make base model trainable overall\n",
    "# base_model.trainable = True\n",
    "\n",
    "# Step 2: freeze everything EXCEPT the last 20 layers\n",
    "# for layer in base_model.layers[:-20]:\n",
    "#     layer.trainable = False\n",
    "\n",
    "# TODO: Re-compile with a much lower learning rate\n",
    "# model.compile(\n",
    "#     optimizer=optimizers.Adam(learning_rate=1e-5),\n",
    "#     loss='categorical_crossentropy',\n",
    "#     metrics=['accuracy']\n",
    "# )\n",
    "\n",
    "# Check how many are now trainable\n",
    "trainable = sum(1 for l in base_model.layers if l.trainable)\n",
    "print(f\"Now trainable layers in ResNet50: {trainable}\")\n",
    "\n",
    "# TODO: Train for 5 more epochs\n",
    "# history_phase2 = model.fit(...)\n",
    "\n",
    "history_phase2 = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reveal_button(\n",
    "    hint_text=\"<code>base_model.trainable = True</code> first, then loop: \"\n",
    "              \"<code>for layer in base_model.layers[:-20]: layer.trainable = False</code>. \"\n",
    "              \"Re-compile with <code>learning_rate=1e-5</code>.\",\n",
    "    solution_code=(\n",
    "        \"base_model = model.layers[0]\\n\"\n",
    "        \"base_model.trainable = True\\n\"\n",
    "        \"for layer in base_model.layers[:-20]:\\n\"\n",
    "        \"    layer.trainable = False\\n\\n\"\n",
    "        \"model.compile(\\n\"\n",
    "        \"    optimizer=optimizers.Adam(learning_rate=1e-5),\\n\"\n",
    "        \"    loss='categorical_crossentropy',\\n\"\n",
    "        \"    metrics=['accuracy']\\n\"\n",
    "        \")\\n\\n\"\n",
    "        \"history_phase2 = model.fit(\\n\"\n",
    "        \"    train_generator, epochs=5, validation_data=val_generator\\n\"\n",
    "        \")\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üéöÔ∏è Task 6: Explore ‚Äî Interactive Training Curves\n",
    "\n",
    "Use the controls below to examine your training history. Look for:\n",
    "- Where does Phase 1 plateau? Where does Phase 2 give an extra push?\n",
    "- Is there a gap between train and val accuracy? What does that mean?\n",
    "- At what epoch does the model first exceed 80% validation accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build combined history from both phases\n",
    "def build_history_dict(h1, h2):\n",
    "    \"\"\"Merge two History objects into one dict for plotting.\"\"\"\n",
    "    combined = {}\n",
    "    for key in h1.history:\n",
    "        p2_vals = h2.history.get(key, [])\n",
    "        combined[key] = h1.history[key] + p2_vals\n",
    "    combined['phase_boundary'] = len(h1.history['accuracy'])\n",
    "    return combined\n",
    "\n",
    "# ‚îÄ‚îÄ Interactive curve explorer ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "metric_toggle = widgets.ToggleButtons(\n",
    "    options=[('Accuracy', 'accuracy'), ('Loss', 'loss')],\n",
    "    description='Metric:', button_style='info'\n",
    ")\n",
    "show_phases = widgets.Checkbox(value=True, description='Show phase boundary')\n",
    "smooth_check = widgets.Checkbox(value=False, description='Smooth curves')\n",
    "out_plot = widgets.Output()\n",
    "\n",
    "def update_curves(change=None):\n",
    "    if history_phase1 is None or history_phase2 is None:\n",
    "        with out_plot:\n",
    "            out_plot.clear_output()\n",
    "            print(\"‚ö†Ô∏è  Run Tasks 4 and 5 first to generate training history.\")\n",
    "        return\n",
    "\n",
    "    hist = build_history_dict(history_phase1, history_phase2)\n",
    "    metric   = metric_toggle.value\n",
    "    val_key  = f'val_{metric}'\n",
    "    boundary = hist['phase_boundary']\n",
    "    epochs   = list(range(1, len(hist[metric]) + 1))\n",
    "\n",
    "    def smooth(vals, w=3):\n",
    "        return [np.mean(vals[max(0,i-w):i+1]) for i in range(len(vals))]\n",
    "\n",
    "    train_vals = smooth(hist[metric])     if smooth_check.value else hist[metric]\n",
    "    val_vals   = smooth(hist[val_key])    if smooth_check.value else hist[val_key]\n",
    "\n",
    "    with out_plot:\n",
    "        out_plot.clear_output(wait=True)\n",
    "        fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "        ax.plot(epochs, train_vals, 'b-o', markersize=5, label=f'Train {metric}', linewidth=2)\n",
    "        ax.plot(epochs, val_vals,   'r-o', markersize=5, label=f'Val {metric}',   linewidth=2)\n",
    "\n",
    "        if show_phases.value:\n",
    "            ax.axvline(x=boundary + 0.5, color='purple', linestyle='--', alpha=0.7, linewidth=2)\n",
    "            ymin, ymax = ax.get_ylim()\n",
    "            ax.text(boundary * 0.5, ymax * 0.97, 'Phase 1\\n(frozen)', ha='center',\n",
    "                    color='purple', fontsize=10, fontweight='bold')\n",
    "            ax.text(boundary + (len(epochs) - boundary) * 0.5, ymax * 0.97, 'Phase 2\\n(fine-tune)',\n",
    "                    ha='center', color='purple', fontsize=10, fontweight='bold')\n",
    "\n",
    "        if metric == 'accuracy':\n",
    "            ax.axhline(y=0.80, color='green', linestyle=':', alpha=0.8, linewidth=1.5,\n",
    "                       label='80% target')\n",
    "            best_val  = max(val_vals)\n",
    "            best_ep   = val_vals.index(best_val) + 1\n",
    "            ax.annotate(f'Best: {best_val:.1%} @ ep{best_ep}',\n",
    "                        xy=(best_ep, best_val), xytext=(best_ep + 1, best_val - 0.05),\n",
    "                        arrowprops=dict(arrowstyle='->', color='red'), color='red', fontsize=10)\n",
    "\n",
    "        ax.set_xlabel('Epoch', fontsize=12)\n",
    "        ax.set_ylabel(metric.capitalize(), fontsize=12)\n",
    "        ax.set_title(f'Training Curves ‚Äî Transfer Learning with ResNet50', fontsize=13, fontweight='bold')\n",
    "        ax.legend(fontsize=11)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "metric_toggle.observe(update_curves, names='value')\n",
    "show_phases.observe(update_curves, names='value')\n",
    "smooth_check.observe(update_curves, names='value')\n",
    "\n",
    "display(widgets.VBox([\n",
    "    widgets.HBox([metric_toggle, show_phases, smooth_check]),\n",
    "    out_plot\n",
    "]))\n",
    "update_curves()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ‚úçÔ∏è Reflection\n",
    "\n",
    "Write a short paragraph (3‚Äì5 sentences) explaining:\n",
    "- Why did transfer learning work so well with only 500 images?\n",
    "- What did Phase 1 learn vs Phase 2?\n",
    "- Would you expect the same result if you trained from scratch? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úèÔ∏è Your reflection:\n",
    "# Transfer learning worked well because...\n",
    "# In Phase 1, the model learned...\n",
    "# In Phase 2, fine-tuning added...\n",
    "# Training from scratch would have..."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
