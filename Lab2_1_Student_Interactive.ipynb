{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hpTQhdLIvOIC"
   },
   "source": [
    "# üß† Lab 2.1: Understanding CNN Layers with VGG16\n",
    "**Module 3: Computer Vision and Image Processing**  \n",
    "B-Tech AI Specialization | Chitkara University | February 2026\n",
    "\n",
    "---\n",
    "\n",
    "## üè• Industry Scenario\n",
    "\n",
    "> A hospital deployed a chest X-ray classifier, but doctors don't trust it ‚Äî they can't see *what* the model is \"looking at\" when it makes decisions. Your job is to **visualize the internal layers of the CNN** to make it interpretable and trustworthy.\n",
    "\n",
    "## üéØ Objective\n",
    "Load a pre-trained VGG16 model, extract feature maps from 3 different layers, and **explore** what the network learns at each depth using interactive tools.\n",
    "\n",
    "**Time:** 90 minutes | **Mode:** Individual\n",
    "\n",
    "---\n",
    "\n",
    "### üìã Lab Flow\n",
    "Each task follows this structure:\n",
    "\n",
    "| Step | What you do |\n",
    "|---|---|\n",
    "| ü§î **Predict** | Answer a quick question *before* coding |\n",
    "| üíª **Code** | Fill in the `TODO` cells |\n",
    "| üí° **Reveal** | Click a button to check your solution |\n",
    "| üéöÔ∏è **Explore** | Use sliders/dropdowns to discover patterns |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y2CC2b9FvOID"
   },
   "source": [
    "## ‚öôÔ∏è Setup ‚Äî Run This First\n",
    "\n",
    "Run the cell below to install packages and set up the interactive tools. **Don't skip this step.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lJgqWZ0yvOID"
   },
   "outputs": [],
   "source": [
    "# Install & import everything needed\n",
    "# (ipywidgets is pre-installed on Colab ‚Äî no pip needed)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML, Code, clear_output\n",
    "\n",
    "print(f\"TensorFlow : {tf.__version__}\")\n",
    "print(f\"ipywidgets : {widgets.__version__}\")\n",
    "print(\"‚úÖ All set ‚Äî you're ready to start!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kF_p-ozzvOIE"
   },
   "source": [
    "### üõ†Ô∏è Helper ‚Äî Reveal Button\n",
    "This sets up the hint/solution buttons used throughout the lab. **Run once, then ignore.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "minUZ4MjvOIE"
   },
   "outputs": [],
   "source": [
    "def reveal_button(hint_text, solution_code):\n",
    "    \"\"\"Creates a paired Hint + Solution reveal widget for Colab.\"\"\"\n",
    "    out = widgets.Output()\n",
    "\n",
    "    hint_btn = widgets.Button(\n",
    "        description='üí° Hint', button_style='info',\n",
    "        layout=widgets.Layout(width='120px', margin='4px')\n",
    "    )\n",
    "    sol_btn = widgets.Button(\n",
    "        description='‚úÖ Solution', button_style='warning',\n",
    "        layout=widgets.Layout(width='140px', margin='4px')\n",
    "    )\n",
    "    hide_btn = widgets.Button(\n",
    "        description='üôà Hide', button_style='',\n",
    "        layout=widgets.Layout(width='100px', margin='4px')\n",
    "    )\n",
    "\n",
    "    def on_hint(b):\n",
    "        with out:\n",
    "            out.clear_output(wait=True)\n",
    "            display(HTML(\n",
    "                f'<div style=\"background:#e3f2fd;color: #1565C0; padding:12px;border-radius:6px;'\n",
    "                f'border-left:4px solid #0D47A1;font-size:14px\">'\n",
    "                f'<b>üí° Hint:</b><br>{hint_text}</div>'\n",
    "            ))\n",
    "\n",
    "    def on_sol(b):\n",
    "        with out:\n",
    "            out.clear_output(wait=True)\n",
    "            display(HTML('<b>‚úÖ Solution:</b>'))\n",
    "            display(Code(solution_code, language='python'))\n",
    "\n",
    "    def on_hide(b):\n",
    "        with out:\n",
    "            out.clear_output()\n",
    "\n",
    "    hint_btn.on_click(on_hint)\n",
    "    sol_btn.on_click(on_sol)\n",
    "    hide_btn.on_click(on_hide)\n",
    "\n",
    "    row = widgets.HBox([hint_btn, sol_btn, hide_btn])\n",
    "    display(row, out)\n",
    "\n",
    "print(\"reveal_button() is ready ‚úÖ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ItTbZktvOIE"
   },
   "source": [
    "---\n",
    "## Task 1: Load VGG16\n",
    "\n",
    "### ü§î Predict First\n",
    "\n",
    "Before running any code, answer these in the cell below:\n",
    "1. VGG16 has 16 layers ‚Äî what do you think those 16 layers consist of?\n",
    "2. What does \"pre-trained on ImageNet\" mean? Why does it matter here?\n",
    "3. If you load the model with `weights=None`, what would the feature maps look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "caB3345NvOIE"
   },
   "outputs": [],
   "source": [
    "# ‚úèÔ∏è Write your predictions here (as comments ‚Äî no code needed yet)\n",
    "\n",
    "# 1. The 16 layers are probably...\n",
    "\n",
    "# 2. Pre-trained on ImageNet means...\n",
    "\n",
    "# 3. With weights=None, feature maps would look like..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1w-k1mI3vOIE"
   },
   "source": [
    "### üíª Your Turn ‚Äî Load the Model\n",
    "\n",
    "Fill in the `TODO` below. You need:\n",
    "- `weights='imagenet'` ‚Äî use pre-trained weights\n",
    "- `include_top=True` ‚Äî include the classifier layers\n",
    "- `input_shape=(224, 224, 3)` ‚Äî VGG16's required input size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JQSuXJI9vOIE"
   },
   "outputs": [],
   "source": [
    "# TODO: Load VGG16 with pre-trained ImageNet weights\n",
    "model = VGG16(\n",
    "    # weights=...,\n",
    "    # include_top=...,\n",
    "    # input_shape=...\n",
    ")\n",
    "\n",
    "# TODO: Print the model summary\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zz8OqSXLvOIE"
   },
   "source": [
    "#### üí° Stuck? Use the buttons below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2DOyGEAKvOIE"
   },
   "outputs": [],
   "source": [
    "reveal_button(\n",
    "    hint_text=\"Use <code>VGG16(weights='imagenet', include_top=True, input_shape=(224,224,3))</code>. \"\n",
    "              \"Then call <code>model.summary()</code> on the next line.\",\n",
    "    solution_code=(\n",
    "        \"model = VGG16(weights='imagenet', include_top=True, input_shape=(224, 224, 3))\\n\"\n",
    "        \"model.summary()\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h2253iQJvOIE"
   },
   "source": [
    "### üéöÔ∏è Explore: Layer Architecture\n",
    "\n",
    "Once the model loads, use the dropdown below to inspect any layer ‚Äî see its output shape and what type it is. **Experiment before moving on.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fWvPYV0OvOIE"
   },
   "outputs": [],
   "source": [
    "# Interactive layer inspector\n",
    "# (Run model.summary() first so 'model' exists)\n",
    "\n",
    "layer_dropdown = widgets.Dropdown(\n",
    "    options=[(f\"{i:2d}. {l.name}\", i) for i, l in enumerate(model.layers)],\n",
    "    description='Layer:',\n",
    "    layout=widgets.Layout(width='420px')\n",
    ")\n",
    "out_layer = widgets.Output()\n",
    "\n",
    "def on_layer_change(change):\n",
    "    with out_layer:\n",
    "        out_layer.clear_output(wait=True)\n",
    "        idx = change['new']\n",
    "        layer = model.layers[idx]\n",
    "        in_shape  = getattr(layer, 'input_shape',  'N/A')\n",
    "        out_shape = getattr(layer, 'output_shape', 'N/A')\n",
    "        params    = layer.count_params()\n",
    "        html = (\n",
    "            f'<div style=\"background:#f9f9f9;padding:12px;border-radius:6px;'\n",
    "            f'border-left:4px solid #4CAF50;font-family:monospace;font-size:13px\">'\n",
    "            f'<b>Name:</b>  {layer.name}<br>'\n",
    "            f'<b>Type:</b>  {layer.__class__.__name__}<br>'\n",
    "            f'<b>Input:</b> {in_shape}<br>'\n",
    "            f'<b>Output:</b>{out_shape}<br>'\n",
    "            f'<b>Params:</b>{params:,}'\n",
    "            f'</div>'\n",
    "        )\n",
    "        display(HTML(html))\n",
    "\n",
    "layer_dropdown.observe(on_layer_change, names='value')\n",
    "display(widgets.VBox([\n",
    "    widgets.HTML('<b>üîç Layer Inspector ‚Äî select any layer:</b>'),\n",
    "    layer_dropdown,\n",
    "    out_layer\n",
    "]))\n",
    "on_layer_change({'new': 0})  # trigger initial display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "riCpeKWQvOIF"
   },
   "source": [
    "**‚úèÔ∏è Quick Questions (answer in a comment below):**\n",
    "- Which layer causes the spatial size to shrink from 224‚Üí112? What type is it?\n",
    "- How many total parameters does VGG16 have?\n",
    "- Which layers have *no* trainable parameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jBZ3XLp9vOIF"
   },
   "outputs": [],
   "source": [
    "# Your answers:\n",
    "# Spatial shrink happens at...\n",
    "# Total params:\n",
    "# Layers with no params:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U5e7ke5ivOIF"
   },
   "source": [
    "---\n",
    "## Task 2: Select 3 Layers at Different Depths\n",
    "\n",
    "We'll extract feature maps from **3 carefully chosen layers** ‚Äî one early, one middle, one deep.\n",
    "\n",
    "### ü§î Predict First\n",
    "Based on what you know about CNNs, predict what you'll see at each depth:\n",
    "\n",
    "| Layer | Your prediction |\n",
    "|---|---|\n",
    "| Very first conv layer | ? |\n",
    "| Middle conv layer | ? |\n",
    "| Last conv layer | ? |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ui8cUIxgvOIF"
   },
   "outputs": [],
   "source": [
    "# ‚úèÔ∏è Write your predictions here\n",
    "# Early layer will show...\n",
    "# Middle layer will show...\n",
    "# Deep layer will show..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tb8uejLrvOIF"
   },
   "source": [
    "### üíª Your Turn ‚Äî Define the Layer Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JtiZ-_8yvOIF"
   },
   "outputs": [],
   "source": [
    "# TODO: Fill in the 3 layer names\n",
    "# Use the Layer Inspector above to find them if needed\n",
    "\n",
    "layer_names = [\n",
    "    # 'block1_conv1',   # Early  ‚Äî first convolution\n",
    "    # '...',            # Middle ‚Äî around block 3\n",
    "    # '...',            # Deep   ‚Äî last conv before pooling\n",
    "]\n",
    "\n",
    "# Verify they exist\n",
    "all_names = [l.name for l in model.layers]\n",
    "for name in layer_names:\n",
    "    status = '‚úÖ' if name in all_names else '‚ùå NOT FOUND'\n",
    "    print(f\"{status}  {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q-YD9xkAvOIF"
   },
   "source": [
    "#### üí° Stuck?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iVKXFW_SvOIF"
   },
   "outputs": [],
   "source": [
    "reveal_button(\n",
    "    hint_text=\"Look for <b>block1_conv1</b> (early), <b>block3_conv3</b> (middle), \"\n",
    "              \"and <b>block5_conv3</b> (deep). Use the Layer Inspector above to confirm they exist.\",\n",
    "    solution_code=(\n",
    "        \"layer_names = [\\n\"\n",
    "        \"    'block1_conv1',  # Early:  224x224, 64 filters\\n\"\n",
    "        \"    'block3_conv3',  # Middle:  56x56, 256 filters\\n\"\n",
    "        \"    'block5_conv3',  # Deep:    14x14, 512 filters\\n\"\n",
    "        \"]\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dWeH5pzvvOIF"
   },
   "source": [
    "---\n",
    "## Task 3: Build Feature Extractor Sub-Models\n",
    "\n",
    "A **feature extractor** is a sub-model that intercepts VGG16 at a specific layer and returns the activations *at that point*, instead of the final class prediction.\n",
    "\n",
    "```\n",
    "VGG16: Input ‚Üí [block1] ‚Üí [block2] ‚Üí [block3] ‚Üí ... ‚Üí [Dense] ‚Üí 1000 classes\n",
    "                   ‚Üë                      ‚Üë                  ‚Üë\n",
    "           tap here (early)       tap here (mid)      tap here (deep)\n",
    "```\n",
    "\n",
    "### üíª Your Turn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E_u18UkTvOIF"
   },
   "outputs": [],
   "source": [
    "# TODO: Build a dict of feature extractor sub-models\n",
    "# For each layer name, create: Model(inputs=model.input, outputs=<that layer's output>)\n",
    "\n",
    "feature_extractors = {}\n",
    "\n",
    "# for name in layer_names:\n",
    "#     output = model.get_layer(name).output\n",
    "#     feature_extractors[name] = Model(inputs=model.input, outputs=output)\n",
    "\n",
    "# Check your work:\n",
    "for name, extractor in feature_extractors.items():\n",
    "    print(f\"'{name}': output shape = {extractor.output_shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wDtBWL1BvOIF"
   },
   "outputs": [],
   "source": [
    "reveal_button(\n",
    "    hint_text=\"Use <code>model.get_layer(name).output</code> to get the layer's output tensor, \"\n",
    "              \"then wrap it: <code>Model(inputs=model.input, outputs=output)</code>.\",\n",
    "    solution_code=(\n",
    "        \"feature_extractors = {}\\n\"\n",
    "        \"for name in layer_names:\\n\"\n",
    "        \"    output = model.get_layer(name).output\\n\"\n",
    "        \"    feature_extractors[name] = Model(inputs=model.input, outputs=output)\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W8FoGdarvOIF"
   },
   "source": [
    "---\n",
    "## Task 4: Load & Preprocess the Test Image\n",
    "\n",
    "VGG16 requires a very specific input format:\n",
    "- Shape: `(1, 224, 224, 3)` ‚Äî batch of 1 image, 224√ó224, 3 channels\n",
    "- Preprocessing: `preprocess_input()` subtracts the ImageNet mean pixel values\n",
    "\n",
    "### üíª Your Turn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kdqLnG0rvOIF"
   },
   "outputs": [],
   "source": [
    "# Load a dog image\n",
    "# https://images.pexels.com/photos/672244/pexels-photo-672244.jpeg\n",
    "# Check the filters\n",
    "\n",
    "# After you run the remaining cells, come back here and restart as follows:\n",
    "# Load a Chest X-ray image\n",
    "# Source and use an opensource Chest X-Ray image - not a random one\n",
    "\n",
    "img_url = \"\"\n",
    "response = requests.get(img_url)\n",
    "img = Image.open(BytesIO(response.content)).convert('RGB')\n",
    "\n",
    "# TODO: Step 1 ‚Äî Resize to (224, 224)\n",
    "img_resized = None  # img.resize(...)\n",
    "\n",
    "# TODO: Step 2 ‚Äî Convert to numpy array\n",
    "img_array = None  # np.array(...)\n",
    "\n",
    "# TODO: Step 3 ‚Äî Add batch dimension ‚Üí shape (1, 224, 224, 3)\n",
    "img_batch = None  # np.expand_dims(...)\n",
    "\n",
    "# TODO: Step 4 ‚Äî Apply VGG16 preprocessing\n",
    "img_preprocessed = None  # preprocess_input(img_batch.copy())\n",
    "\n",
    "# Show the image\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.imshow(img_resized)\n",
    "plt.title(\"Test Image\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "print(f\"Final shape: {img_preprocessed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7IviG-7hvOIF"
   },
   "outputs": [],
   "source": [
    "reveal_button(\n",
    "    hint_text=\"<code>img.resize((224,224))</code> ‚Üí <code>np.array()</code> ‚Üí \"\n",
    "              \"<code>np.expand_dims(..., axis=0)</code> ‚Üí <code>preprocess_input()</code>\",\n",
    "    solution_code=(\n",
    "        \"img_resized     = img.resize((224, 224))\\n\"\n",
    "        \"img_array       = np.array(img_resized, dtype=np.float32)\\n\"\n",
    "        \"img_batch       = np.expand_dims(img_array, axis=0)\\n\"\n",
    "        \"img_preprocessed = preprocess_input(img_batch.copy())\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R9r88AgkvOIF"
   },
   "source": [
    "---\n",
    "## Task 5: Extract the Feature Maps\n",
    "\n",
    "Run the preprocessed image through each sub-model to get the activations. We'll store them in a dictionary ‚Äî then use the interactive explorer in Task 6.\n",
    "\n",
    "### üíª Your Turn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Sa3gEzxvOIF"
   },
   "outputs": [],
   "source": [
    "# TODO: For each extractor, run the image through it and store the result\n",
    "all_feature_maps = {}\n",
    "\n",
    "# for name, extractor in feature_extractors.items():\n",
    "#     all_feature_maps[name] = extractor.predict(img_preprocessed, verbose=0)\n",
    "#     print(f\"'{name}' ‚Üí shape: {all_feature_maps[name].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zLKLdoCZvOIF"
   },
   "outputs": [],
   "source": [
    "reveal_button(\n",
    "    hint_text=\"Call <code>extractor.predict(img_preprocessed, verbose=0)</code> and store the result.\",\n",
    "    solution_code=(\n",
    "        \"all_feature_maps = {}\\n\"\n",
    "        \"for name, extractor in feature_extractors.items():\\n\"\n",
    "        \"    all_feature_maps[name] = extractor.predict(img_preprocessed, verbose=0)\\n\"\n",
    "        \"    fmap = all_feature_maps[name]\\n\"\n",
    "        \"    print(f\\\"'{name}' ‚Üí shape: {fmap.shape}  (spatial: {fmap.shape[1]}x{fmap.shape[2]}, filters: {fmap.shape[3]})\\\")\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xsWvq6O0vOIF"
   },
   "source": [
    "---\n",
    "## üéöÔ∏è Task 6: Interactive Feature Map Explorer\n",
    "\n",
    "Now for the fun part. Use the controls below to explore **any filter, at any layer, with any colormap**.\n",
    "\n",
    "**Things to try:**\n",
    "- Start at `block1_conv1`, scroll through filters 0‚Äì10. Do they look like edges?\n",
    "- Switch to `block5_conv3`. Do most filters look **dark** (inactive)? Why?\n",
    "- Try the `gray` colormap ‚Äî does it feel different from `viridis`?\n",
    "- Find the filter with the **highest mean activation** at each layer (it's highlighted in the stats panel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yEIgUoytvOIF"
   },
   "outputs": [],
   "source": [
    "# ‚îÄ‚îÄ Interactive Feature Map Explorer ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# Make sure all_feature_maps is populated (run Task 5 first!)\n",
    "\n",
    "# Build controls\n",
    "layer_select = widgets.Dropdown(\n",
    "    options=layer_names,\n",
    "    value=layer_names[0],\n",
    "    description='Layer:',\n",
    "    style={'description_width': '60px'},\n",
    "    layout=widgets.Layout(width='280px')\n",
    ")\n",
    "\n",
    "filter_slider = widgets.IntSlider(\n",
    "    min=0, max=63, step=1, value=0,\n",
    "    description='Filter #:',\n",
    "    style={'description_width': '70px'},\n",
    "    layout=widgets.Layout(width='380px'),\n",
    "    continuous_update=False\n",
    ")\n",
    "\n",
    "cmap_select = widgets.Dropdown(\n",
    "    options=['viridis', 'plasma', 'inferno', 'magma', 'gray', 'hot', 'RdBu_r'],\n",
    "    value='viridis',\n",
    "    description='Colormap:',\n",
    "    style={'description_width': '80px'},\n",
    "    layout=widgets.Layout(width='220px')\n",
    ")\n",
    "\n",
    "stats_out = widgets.Output()\n",
    "plot_out  = widgets.Output()\n",
    "\n",
    "def update_explorer(change=None):\n",
    "    layer_name  = layer_select.value\n",
    "    filter_idx  = filter_slider.value\n",
    "    cmap        = cmap_select.value\n",
    "\n",
    "    if layer_name not in all_feature_maps:\n",
    "        with plot_out:\n",
    "            plot_out.clear_output()\n",
    "            print(\"‚ö†Ô∏è  Run Task 5 first to compute feature maps!\")\n",
    "        return\n",
    "\n",
    "    fmaps = all_feature_maps[layer_name]   # shape: (1, H, W, num_filters)\n",
    "    num_filters = fmaps.shape[-1]\n",
    "\n",
    "    # Update slider max to match this layer's filter count\n",
    "    filter_slider.max = num_filters - 1\n",
    "    filter_idx = min(filter_idx, num_filters - 1)\n",
    "\n",
    "    activation = fmaps[0, :, :, filter_idx]   # (H, W)\n",
    "\n",
    "    # ‚îÄ‚îÄ Stats panel ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    mean_per_filter = fmaps[0].mean(axis=(0, 1))\n",
    "    top_filter      = int(np.argmax(mean_per_filter))\n",
    "    pct_active      = float(np.mean(activation > 0)) * 100\n",
    "\n",
    "    with stats_out:\n",
    "        stats_out.clear_output(wait=True)\n",
    "        display(HTML(\n",
    "            f'<div style=\"background:#f0f4ff;padding:10px;border-radius:6px;'\n",
    "            f'font-family:monospace;font-size:13px;line-height:1.7\">'\n",
    "            f'<b>Layer:</b>  {layer_name}<br>'\n",
    "            f'<b>Spatial:</b> {fmaps.shape[1]}√ó{fmaps.shape[2]} px<br>'\n",
    "            f'<b>Filters:</b> {num_filters} total<br>'\n",
    "            f'<hr style=\"margin:5px 0\">'\n",
    "            f'<b>Selected filter {filter_idx}:</b><br>'\n",
    "            f'&nbsp; Min: {activation.min():.3f}<br>'\n",
    "            f'&nbsp; Max: {activation.max():.3f}<br>'\n",
    "            f'&nbsp; Mean: {activation.mean():.3f}<br>'\n",
    "            f'&nbsp; % Active: {pct_active:.1f}%<br>'\n",
    "            f'<hr style=\"margin:5px 0\">'\n",
    "            f'<b>üèÜ Most active filter:</b> #{top_filter} '\n",
    "            f'(mean={mean_per_filter[top_filter]:.3f})'\n",
    "            f'</div>'\n",
    "        ))\n",
    "\n",
    "    # ‚îÄ‚îÄ Plot ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    with plot_out:\n",
    "        plot_out.clear_output(wait=True)\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(14, 4.5))\n",
    "\n",
    "        # Left: original image\n",
    "        axes[0].imshow(img_resized)\n",
    "        axes[0].set_title('Original Image', fontsize=12)\n",
    "        axes[0].axis('off')\n",
    "\n",
    "        # Middle: selected filter\n",
    "        im = axes[1].imshow(activation, cmap=cmap)\n",
    "        axes[1].set_title(\n",
    "            f'{layer_name}\\nFilter #{filter_idx} | mean={activation.mean():.3f}',\n",
    "            fontsize=11\n",
    "        )\n",
    "        axes[1].axis('off')\n",
    "        plt.colorbar(im, ax=axes[1], fraction=0.046, pad=0.04)\n",
    "\n",
    "        # Right: top activated filter\n",
    "        top_activation = fmaps[0, :, :, top_filter]\n",
    "        im2 = axes[2].imshow(top_activation, cmap=cmap)\n",
    "        axes[2].set_title(\n",
    "            f'üèÜ Most Active Filter #{top_filter}\\nmean={mean_per_filter[top_filter]:.3f}',\n",
    "            fontsize=11\n",
    "        )\n",
    "        axes[2].axis('off')\n",
    "        plt.colorbar(im2, ax=axes[2], fraction=0.046, pad=0.04)\n",
    "\n",
    "        plt.suptitle(f'Feature Map Explorer ‚Äî {layer_name}', fontsize=13, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Wire up observers\n",
    "layer_select.observe(update_explorer, names='value')\n",
    "filter_slider.observe(update_explorer, names='value')\n",
    "cmap_select.observe(update_explorer, names='value')\n",
    "\n",
    "# Layout\n",
    "controls = widgets.VBox([\n",
    "    widgets.HTML('<b>üéöÔ∏è Controls:</b>'),\n",
    "    widgets.HBox([layer_select, cmap_select]),\n",
    "    filter_slider,\n",
    "])\n",
    "main_panel = widgets.HBox([\n",
    "    widgets.VBox([controls, stats_out], layout=widgets.Layout(width='310px')),\n",
    "    plot_out\n",
    "])\n",
    "display(main_panel)\n",
    "update_explorer()  # initial render"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O9bSbu_cvOIG"
   },
   "source": [
    "---\n",
    "## Task 7: Save the 4√ó4 Grid Visualizations\n",
    "\n",
    "For submission, generate and save a **4√ó4 grid** (first 16 filters) for each of the 3 layers.\n",
    "\n",
    "### üíª Your Turn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yQDpfqAUvOIG"
   },
   "outputs": [],
   "source": [
    "def save_grid(layer_name, cmap='viridis'):\n",
    "    \"\"\"Display and save a 4x4 grid of the first 16 filters for a layer.\"\"\"\n",
    "    fmaps = all_feature_maps[layer_name]   # (1, H, W, num_filters)\n",
    "\n",
    "    fig, axes = plt.subplots(4, 4, figsize=(12, 12))\n",
    "    fig.suptitle(\n",
    "        f'Feature Maps ‚Äî {layer_name}\\n'\n",
    "        f'Spatial: {fmaps.shape[1]}√ó{fmaps.shape[2]} | Filters shown: 16 of {fmaps.shape[3]}',\n",
    "        fontsize=13, fontweight='bold'\n",
    "    )\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        # TODO: Get the i-th filter activation from fmaps\n",
    "        activation = None   # fmaps[0, :, :, i]\n",
    "\n",
    "        # TODO: Display it with imshow using the given cmap\n",
    "        # ax.imshow(...)\n",
    "\n",
    "        mean_val = 0 if activation is None else activation.mean()\n",
    "        ax.set_title(f'Filter {i}  Œº={mean_val:.2f}', fontsize=8)\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    filename = f'feature_maps_{layer_name}.png'\n",
    "    plt.savefig(filename, dpi=100, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(f\"‚úÖ Saved: {filename}\")\n",
    "\n",
    "# TODO: Call save_grid() for all 3 layers\n",
    "# for name in layer_names:\n",
    "#     save_grid(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vkv1RdaCvOIG"
   },
   "outputs": [],
   "source": [
    "reveal_button(\n",
    "    hint_text=\"Inside the loop: <code>activation = fmaps[0, :, :, i]</code> then <code>ax.imshow(activation, cmap=cmap)</code>\",\n",
    "    solution_code=(\n",
    "        \"# Inside save_grid():\\n\"\n",
    "        \"activation = fmaps[0, :, :, i]\\n\"\n",
    "        \"ax.imshow(activation, cmap=cmap)\\n\\n\"\n",
    "        \"# Then call for all layers:\\n\"\n",
    "        \"for name in layer_names:\\n\"\n",
    "        \"    save_grid(name)\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WTB46UJrvOIG"
   },
   "source": [
    "---\n",
    "## ‚úçÔ∏è Reflection\n",
    "\n",
    "You've now *seen* what each layer detects. Write **3 sentences** below ‚Äî one per layer ‚Äî describing your observations.\n",
    "\n",
    "Guiding questions:\n",
    "- Do early activations look similar to the original image, or very different?\n",
    "- In deep layers, why are most filters **all dark** (zero activation)?\n",
    "- How does this visualization help **doctors trust** an X-ray classifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DY0zGaRXvOIG"
   },
   "outputs": [],
   "source": [
    "# ‚úèÔ∏è Your reflection (as Python comments is fine)\n",
    "\n",
    "# block1_conv1 (Early):\n",
    "#\n",
    "\n",
    "# block3_conv3 (Middle):\n",
    "#\n",
    "\n",
    "# block5_conv3 (Deep):\n",
    "#\n",
    "\n",
    "# How this builds trust in the hospital scenario:\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tOeDwHamvOIG"
   },
   "source": [
    "---\n",
    "## üì§ Submission Checklist\n",
    "\n",
    "Before submitting this notebook:\n",
    "\n",
    "- [ ] All code cells are **run** with outputs visible\n",
    "- [ ] `feature_maps_block1_conv1.png` saved\n",
    "- [ ] `feature_maps_block3_conv3.png` saved\n",
    "- [ ] `feature_maps_block5_conv3.png` saved\n",
    "- [ ] Reflection section filled in with 3 sentences\n",
    "- [ ] Share this `.ipynb` (File ‚Üí Download or Share via Colab link)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
